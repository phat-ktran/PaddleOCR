Global:
  use_gpu: true
  epoch_num: 20
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_svtrnet_base_ch_exp_a5.1.0/
  save_epoch_step: 1
  eval_batch_step: [2000, 1000]
  cal_metric_during_train: true
  pretrained_model: null
  checkpoints: null
  save_inference_dir: null
  use_visualdl: false
  infer_img: null
  character_dict_path: ppocr/utils/dict/PP-Thesis/hisdoc1b_19k.txt
  max_text_length: &max_text_length 40
  infer_mode: false
  use_space_char: false
  save_res_path: null
  use_amp: true
  use_wandb: true
  distributed: true
  d2s_train_image_shape: [3, 32, 584]
  
wandb:
  project: "HisDoc1B-5M"
  entity: "trankim147-vnu-hcmus"
  name: "A5.1.0"

Optimizer:
  name: AdamW
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.e-8
  weight_decay: 0.05
  no_weight_decay_name: norm
  one_dim_param_no_weight_decay: True
  lr:
    name: Cosine
    learning_rate: 0.001
    warmup_epoch: 2

Architecture:
  model_type: rec
  algorithm: SVTR
  Transform: null
  Backbone:
    name: SVTRNet
    img_size:
      - 32
      - 584
    out_char_num: 40 # W//4 or W//8 or W/12
    out_channels: 256
    patch_merging: Conv
    patch_size: [4, 8]
    embed_dim:
      - 128
      - 256
      - 384
    depth:
      - 3
      - 6
      - 9
    num_heads:
      - 4
      - 8
      - 12
    mixer:
      - Local
      - Local
      - Local
      - Local
      - Local
      - Local
      - Local
      - Local
      - Global
      - Global
      - Global
      - Global
      - Global
      - Global
      - Global
      - Global
      - Global
      - Global
    local_mixer:
      - - 7
        - 11
      - - 7
        - 11
      - - 7
        - 11
    last_stage: false
    prenorm: true
  Neck:
    name: SequenceEncoder
    encoder_type: reshape
  Head:
    name: MultiHead
    use_pool: false
    use_pos: true
    head_list:
      - CTCHead:
          Neck:
            name: svtr
            dims: 160
            depth: 2
            hidden_dims: 160
            kernel_size: [1, 3]
            use_guide: True
          Head:
            fc_decay: 0.00001
      - NRTRHead:
          nrtr_dim: 384
          max_text_length: *max_text_length

Loss:
  name: MultiLoss
  loss_config_list:
    - CTCLoss:
    - NRTRLoss:

PostProcess:
  name: CTCLabelDecode

Metric:
  name: RecMetric
  main_indicator: acc

Train:
  dataset:
    name: UnifiedMultiScaleLMDBDataSet
    ds_width: false
    data_dir: ./train_data/rec/full
    val_ids: ./train_data/rec/val_ids.json
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecAug:
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - KeepKeys:
          keep_keys:
            - image
            - label_ctc
            - label_gtc
            - length
            - valid_ratio
  sampler:
    name: MultiScaleSampler
    scales: [[584, 32], [584, 48], [584, 64]]
    first_bs: &bs 128
    fix_bs: false
    divided_factor: [8, 16] # w, h
    is_training: True
  loader:
    shuffle: true
    batch_size_per_card: *bs
    drop_last: true
    num_workers: 16

Eval:
  dataset:
    name: UnifiedLMDBDataSet
    data_dir: ./train_data/rec/full
    val_ids: ./train_data/rec/val_ids.json
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - RecResizeImg:
          image_shape: [3, 32, 584]
      - KeepKeys:
          keep_keys:
            - image
            - label
            - length
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 512
    num_workers: 12
