Global:
  model_name: PP-OCRv4_server_rec # To use static model for inference.
  debug: false
  use_gpu: true
  epoch_num: 20
  distributed: true
  eval_batch_step: [10000, 2500]
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_ppocrv4_base_ch_exp_5.2.1
  save_epoch_step: 1
  cal_metric_during_train: true
  calc_epoch_interval: 1
  pretrained_model: null
  checkpoints: null
  character_dict_path: ./ppocr/utils/dict/PP-Thesis/hisdoc1b_19k.txt
  save_inference_dir:
  use_visualdl: false
  infer_img: null
  save_res_path: null
  infer_mode: false
  use_space_char: false
  max_text_length: &max_text_length 40
  use_wandb: true
  d2s_train_image_shape: [3, 32, 640]

wandb:
  project: "HisDoc1B-10M"
  entity: "trankim147-vnu-hcmus"
  name: "A5.2.1"
  
Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  lr:
    name: Cosine
    learning_rate: 0.001
    warmup_epoch: 3
  regularizer:
    name: L2
    factor: 3.0e-05

Architecture:
  model_type: rec
  algorithm: SVTR_HGNet
  Transform:
  Backbone:
    name: PPHGNet_small
    out_char_num: *max_text_length
    layer_num: 6
    stem_channels: [64, 64, 128]
    out_avg_kernel_size: [2,4]
    stage_config_rec:
      # in_channels, mid_channels, out_channels, blocks, downsample
      stage1: [128, 128, 256, 1, True, [2, 1]]
      stage2: [256, 160, 512, 1, True, [1, 2]]
      stage3: [512, 192, 768, 2, True, [2, 1]]
      stage4: [768, 224, 1024, 1, True, [2, 1]]
  Head:
    name: MultiHead
    head_list:
      - CTCHead:
          Neck:
            name: svtr
            dims: 120
            depth: 2
            hidden_dims: 120
            kernel_size: [1, 3]
            use_guide: True
          Head:
            fc_decay: 0.00001
      - NRTRHead:
          nrtr_dim: 384
          max_text_length: *max_text_length

Loss:
  name: MultiLoss
  loss_config_list:
    - CTCLoss:
    - NRTRLoss:

PostProcess:
  name: CTCLabelDecode

Metric:
  name: RecMetric
  main_indicator: acc

Train:
  dataset:
    name: UnifiedMultiScaleLMDBDataSet
    ds_width: false
    data_dir: ./train_data/rec/full
    val_ids: ./train_data/rec/val_ids.json
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecConAug:
          prob: 0.5
          ext_data_num: 2
          image_shape: [32, 640, 3]
          max_text_length: *max_text_length
      - RecAug:
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - KeepKeys:
          keep_keys:
            - image
            - label_ctc
            - label_gtc
            - length
            - valid_ratio
  sampler:
    name: MultiScaleSampler
    scales: [[640, 32], [640, 48], [640, 64]]
    first_bs: &bs 96
    fix_bs: false
    divided_factor: [8, 16] # w, h
    is_training: True
  loader:
    shuffle: true
    batch_size_per_card: *bs
    drop_last: true
    num_workers: 8

Eval:
  dataset:
    name: UnifiedLMDBDataSet
    ds_width: false
    data_dir: ./train_data/rec/full
    val_ids: ./train_data/rec/val_ids.json
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - RecResizeImg:
          image_shape: [3, 32, 640]
      - KeepKeys:
          keep_keys:
            - image
            - label_ctc
            - label_gtc
            - length
            - valid_ratio
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 640
    num_workers: 4
