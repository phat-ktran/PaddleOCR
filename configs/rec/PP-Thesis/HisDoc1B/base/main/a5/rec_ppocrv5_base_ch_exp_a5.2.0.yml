Global:
  debug: false
  use_gpu: true
  epoch_num: 20
  distributed: true
  eval_batch_step: [0, 4991]
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_ppocrv5_base_ch_exp_a5.2.0
  save_epoch_step: 1
  cal_metric_during_train: true
  calc_epoch_interval: 1

  # vanish gradient combat
  log_grad_norm: false
  #########################

  checkpoints: null
  character_dict_path: ./ppocr/utils/dict/PP-Thesis/hisdoc1b_19k.txt
  save_inference_dir:
  use_visualdl: false
  infer_img: null
  save_res_path: null
  infer_mode: false
  use_space_char: false
  max_text_length: &max_text_length 40
  use_amp: true
  use_wandb: true
  find_unused_parameters: true

wandb:
  project: "HisDoc1B-5M"
  entity: "trankim147-vnu-hcmus"
  name: "A5.2.0"

Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  lr:
    name: Cosine
    learning_rate: 0.001
    warmup_epoch: 2
  regularizer:
    name: L2
    factor: 3.0e-05
Architecture:
  model_type: rec
  name: DistillationModel
  algorithm: Distillation
  Models:
    Teacher:
      pretrained: ./output/rec_svtrnet_base_ch_exp_a5.1.0/best_accuracy
      freeze_params: true
      return_all_feats: true
      model_type: rec
      algorithm: SVTR
      Transform: null
      Backbone:
        name: SVTRNet
        img_size:
          - 32
          - 640
        out_char_num: *max_text_length
        out_channels: 256
        patch_merging: Conv
        embed_dim:
          - 128
          - 256
          - 384
        depth:
          - 3
          - 6
          - 6
        num_heads:
          - 4
          - 8
          - 12
        mixer:
          - Local
          - Local
          - Local
          - Local
          - Local
          - Local
          - Local
          - Local
          - Global
          - Global
          - Global
          - Global
          - Global
          - Global
          - Global
          - Global
          - Global
          - Global
        local_mixer:
          - - 7
            - 11
          - - 7
            - 11
          - - 7
            - 11
        last_stage: true
        prenorm: true
      Neck:
        name: SequenceEncoder
        encoder_type: reshape
      Head:
        name: CTCHead

    Student:
      pretrained: https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_server_rec_pretrained.pdparams
      freeze_params: false
      mapped_key_prefixes:
        "head.ctc_encoder": "neck"
      return_all_feats: true
      model_type: rec
      algorithm: SVTR_HGNet
      Transform: null
      Backbone:
        name: PPHGNetV2_B4
        text_rec: True
        stem_channels: [3, 32, 48]
        out_char_num: *max_text_length # for training mode
        out_avg_kernel_size: [4, 4] # for inference mode
        stage_config_rec:
          # in_channels, mid_channels, out_channels, num_blocks, is_downsample, light_block, kernel_size, layer_num, stride
          stage1: [48, 48, 128, 1, True, False, 3, 6, [2, 1]]
          stage2: [128, 96, 512, 1, True, False, 3, 6, [1, 2]]
          stage3: [512, 192, 1024, 3, True, True, 5, 6, [2, 1]]
          stage4: [1024, 384, 2048, 1, True, True, 5, 6, [2, 1]]
      Neck:
        name: SequenceEncoder
        encoder_type: svtr
        dims: 120
        depth: 2
        hidden_dims: 120
        kernel_size: [1, 3]
        use_guide: True
      Head:
        name: CTCHead

Loss:
  name: CombinedLoss
  loss_config_list:
    - DistillationDKDLoss:
        weight: 0.1
        model_name_pairs:
          - - Student
            - Teacher
        key: head_out
        multi_head: &multi_head false
        alpha: 1.0
        beta: 2.0
        dis_head: ctc
        name: dkd
    - DistillationCTCLoss:
        weight: 1.0
        model_name_list:
          - Student
        key: head_out
        multi_head: false
    - DistillCTCLogits:
        weight: 1.0
        reduction: mean
        model_name_pairs:
          - - Student
            - Teacher
        key: head_out
        inner_key: null

PostProcess:
  name: DistillationCTCLabelDecode
  model_name:
    - Student
  key: head_out
  multi_head: *multi_head

Metric:
  name: DistillationMetric
  base_metric_name: RecMetric
  main_indicator: acc
  key: Student
  ignore_space: true

Train:
  dataset:
    name: UnifiedLMDBDataSet
    data_dir: ./train_data/rec/full
    val_ids: ./train_data/rec/val_ids.json
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecAug:
      - CTCLabelEncode: null
      - SVTRRecResizeImg:
          image_shape:
            - 3
            - 32
            - 640
          padding: true
      - KeepKeys:
          keep_keys:
            - image
            - label
            - length
  loader:
    shuffle: true
    batch_size_per_card: 128
    drop_last: true
    num_workers: 16

Eval:
  dataset:
    name: UnifiedLMDBDataSet
    data_dir: ./train_data/rec/full
    val_ids: ./train_data/rec/val_ids.json
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - CTCLabelEncode: null
      - SVTRRecResizeImg:
          image_shape:
            - 3
            - 32
            - 640
          padding: true
      - KeepKeys:
          keep_keys:
            - image
            - label
            - length
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 384
    num_workers: 12
