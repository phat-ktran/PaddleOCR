Global:
  debug: false
  use_gpu: true
  epoch_num: 20
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_ppv5ss1_svtrv2_base_ch_exp_4v1/
  save_epoch_step: 1
  eval_batch_step:
    - 13880
    - 2000
  cal_metric_during_train: true
  pretrained_model:
  checkpoints:
  save_inference_dir:
  use_visualdl: false
  infer_img: null
  character_dict_path: ppocr/utils/dict/PP-Thesis/hisdoc1b_ss1.txt
  max_text_length: &max_text_length 40
  infer_mode: false
  use_space_char: false
  save_res_path: null
  use_amp: true
  use_wandb: true
  distributed: true
  huggingface:
    push_to_hub: true
    hf_token: null
    repo_id: "PPThes/checkpoints"
    repo_type: "dataset"
    ignore_patterns: "**/wandb/*"
    run_as_future: true
  d2s_train_image_shape: [3, 32, 640]

Optimizer:
  name: AdamW
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.e-8
  weight_decay: 0.05
  no_weight_decay_name: norm
  one_dim_param_no_weight_decay: True
  clip_norm_global: 5.0
  # lr:
  #   name: Cosine
  #   learning_rate: 0.001 # 8gpus 192bs
  #   warmup_epoch: 5
  lr:
    name: Step
    learning_rate: 0.00075 # 12gpus 96bs
    gamma: 0.95
    step_size: 1
    warmup_epoch: 10

Architecture:
  model_type: rec
  algorithm: SVTR_HGNet
  Transform:
  Backbone:
    name: SVTRv2
    use_pos_embed: False
    dims: [128, 256, 384]
    depths: [3, 6, 9]
    num_heads: [4, 8, 12]
    mixer:
      [
        ["Conv", "Conv", "Conv"],
        ["Conv", "Conv", "Global", "Global", "Global", "Global"],
        ["Global", "Global", "Global", "Global", "Global", "Global", "Global", "Global", "Global"],
      ]
    local_k: [[5, 5], [5, 5], [-1, -1]]
    sub_k: [[2, 1], [2, 1], [-1, -1]]
    last_stage: False
    use_pool: True
  Head:
    name: MultiHead
    head_list:
      - CTCHead:
          Neck:
            name: svtr
            dims: 256
            depth: 2
            hidden_dims: 256
            kernel_size: [1, 3]
            use_guide: True
          Head:
            fc_decay: 0.00001
      - NRTRHead:
          nrtr_dim: 384
          max_text_length: *max_text_length
          num_decoder_layers: 2

Loss:
  name: MultiLoss
  loss_config_list:
    - CTCLoss:
    - NRTRLoss:

PostProcess:
  name: CTCLabelDecode

Metric:
  name: RecMetric
  main_indicator: char_acc

Train:
  dataset:
    name: MultiScaleLMDBDataSet
    ds_width: false
    data_dir: ./train_data/rec/train/
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecConAug:
          prob: 0.5
          ext_data_num: 2
          image_shape:
            - 32
            - 640
            - 3
      - RecAug:
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - KeepKeys:
          keep_keys:
            - image
            - label_ctc
            - label_gtc
            - length
            - valid_ratio
  sampler:
    name: MultiScaleSampler
    scales: [[640, 32], [640, 48], [640, 64]]
    first_bs: &bs 192
    fix_bs: false
    divided_factor: [8, 16] # w, h
    is_training: True
  loader:
    shuffle: true
    batch_size_per_card: *bs
    drop_last: true
    num_workers: 12
Eval:
  dataset:
    name: LMDBDataSet
    data_dir: ./train_data/rec/val
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - RecResizeImg:
          image_shape: [3, 32, 640]
      - KeepKeys:
          keep_keys:
            - image
            - label_ctc
            - label_gtc
            - length
            - valid_ratio
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 128
    num_workers: 8
