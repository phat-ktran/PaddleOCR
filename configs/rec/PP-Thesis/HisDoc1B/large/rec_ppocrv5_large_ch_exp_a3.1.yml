Global:
  model_name: PPHGNetV2_B5 # To use static model for inference.
  debug: false
  use_gpu: true
  epoch_num: 100
  distributed: true
  eval_batch_step: [450000, 60000]
  log_smooth_window: 20
  print_batch_step: 12
  save_model_dir: ./output/rec_ppocrv5_large_ch_exp_a3.1
  save_epoch_step: 1
  save_iter_step: 5400
  cal_metric_during_train: true
  calc_epoch_interval: 1
  
  # vanish gradient combat
  log_grad_norm: true
  #########################
  
  # Gradient
  grad_acc: 1
  #########################
  
  pretrained_model: null
  checkpoints: null
  character_dict_path: ./ppocr/utils/dict/PP-Thesis/hisdoc1b_10m.txt
  save_inference_dir:
  use_visualdl: false
  infer_img: null
  save_res_path: null
  infer_mode: false
  use_space_char: false
  max_text_length: &max_text_length 40
  use_amp: true
  use_wandb: true
  d2s_train_image_shape: [3, 32, 584]

wandb:
  project: "Rec-Pretraining-Large"
  entity: "trankim147-vnu-hcmus"
  name: "A3"

Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  clip_norm: 1.0
  lr:
    name: LinearWarmupCosine
    learning_rate: 0.00125
    min_lr: 1.0e-05
    warmup_steps: 72000
  regularizer:
    name: L2
    factor: 1.0e-04

Architecture:
  model_type: rec
  algorithm: SVTR_HGNet
  Transform:
  Backbone:
    name: PPHGNetV2_B5
    text_rec: True
    stem_channels: [3, 48, 64]
    out_char_num: 50 # for training mode
    out_avg_kernel_size: [4, 2] # for inference mode
    stage_config_rec:
      # in_channels, mid_channels, out_channels, num_blocks, is_downsample, light_block, kernel_size, layer_num, stride
      stage1: [64, 64, 128, 1, True, False, 3, 6, [2, 1]]
      stage2: [128, 128, 512, 2, True, False, 3, 6, [1, 2]]
      stage3: [512, 256, 1024, 5, True, True, 5, 6, [2, 1]]
      stage4: [1024, 512, 2048, 2, True, True, 5, 6, [2, 1]]
  Head:
    name: MultiHead
    head_list:
      - CTCHead:
          Neck:
            name: svtr
            dims: 1024
            depth: 2
            hidden_dims: 1024
            kernel_size: [1, 3]
            use_guide: True
          Head:
            fc_decay: 0.00001
      - NRTRHead:
          nrtr_dim: 768
          max_text_length: *max_text_length
          
Loss:
  name: MultiLoss
  weight_1: 1.0
  weight_2: 1.0
  loss_config_list:
    - CTCLoss:
        use_focal_loss: true
    - NRTRLoss:
        smoothing: True

PostProcess:
  name: CTCLabelDecode

Metric:
  name: RecMetric
  main_indicator: acc

Train:
  dataset:
    name: MultiScaleLMDBDataSet
    ds_width: false
    data_dir: ./train_data/rec/train
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecAug:
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - KeepKeys:
          keep_keys:
            - image
            - label_ctc
            - label_gtc
            - length
            - valid_ratio
  sampler:
    name: MultiScaleSampler
    scales: [[584, 32], [584, 48], [584, 64]]
    first_bs: &bs 128
    fix_bs: false
    divided_factor: [8, 16] # w, h
    is_training: True
  loader:
    shuffle: true
    batch_size_per_card: *bs
    drop_last: true
    num_workers: 16

Eval:
  dataset:
    name: LMDBDataSet
    data_dir: ./train_data/rec/val
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - RecResizeImg:
          image_shape: [3, 32, 584]
      - KeepKeys:
          keep_keys:
            - image
            - label
            - length
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 384
    num_workers: 12
