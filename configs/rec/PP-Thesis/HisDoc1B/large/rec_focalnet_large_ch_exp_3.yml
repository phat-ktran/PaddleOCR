Global:
  use_gpu: true
  epoch_num: 200
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_ppv7_focalnet_base_ch_exp_3/
  save_epoch_step: 1
  eval_batch_step:
    - 27760
    - 2000
  cal_metric_during_train: true
  pretrained_model: null
  checkpoints: null
  save_inference_dir: null
  use_visualdl: false
  infer_img: null
  character_dict_path: ppocr/utils/dict/PP-Thesis/hisdoc1b.txt
  max_text_length: 40
  infer_mode: false
  use_space_char: false
  save_res_path: null
  use_amp: true
  distributed: true
  use_wandb: true
  huggingface:
    push_to_hub: false
    hf_token: null
    repo_id: "PPThes/checkpoints"
    repo_type: "dataset"
    ignore_patterns: "**/wandb/*"
    run_as_future: true
  d2s_train_image_shape: [3, 32, 640]

wandb:
  project: "PP-Thesis-Rec-Pretraining"
  entity: "trankim147-vnu-hcmus"
  name: "FocalNet-L-Exp-3"

Optimizer:
  name: AdamW
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.e-8
  weight_decay: 0.05
  no_weight_decay_name: norm
  one_dim_param_no_weight_decay: True
  lr:
    name: Cosine
    learning_rate: 0.00075 # 12gpus 128bs
    warmup_epoch: 5

Architecture:
  model_type: rec
  algorithm: SVTR
  Transform: null
  Backbone:
    name: FocalNet
    img_size:
      - 32
      - 640
    out_char_num: 40 # W//4 or W//8 or W/12
    patch_size: [4, 8]
    patch_mode: "pope" # "pope"
    sub_num: 3 # only when patch_mode is "pope"
    embed_dim: 192
    depths: [6, 6, 9]
    focal_levels: [2, 2, 2]
    focal_windows: [3, 3, 3]
    subsample_stride: [2, 1]
    last_stage: true

    # Normalization
    patch_norm: True
    use_layerscale: False
    layerscale_value: 1e-4
    use_postln: False
    apply_norm_after: True
    normalize_modulator: True

    # Regularization
    drop_rate: 0.1
    drop_path_rate: 0.3
    last_drop: 0.1
  Neck:
    name: SequenceEncoder
    encoder_type: reshape
  Head:
    name: CTCHead

Loss:
  name: CTCLoss

PostProcess:
  name: CTCLabelDecode

Metric:
  name: DistributedRecMetric
  main_indicator: char_acc

Train:
  dataset:
    name: CurriculumLMDBDataSet
    data_dir: ./train_data/rec/train/
    length_steps: [25, 30, 40]
    stage_epochs: [2, 2]
    ext_op_transform_idx: 1
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecConAug:
          prob: 0.5
          ext_data_num: 2
          image_shape:
            - 32
            - 640
            - 3
      - RecAug: null
      - CTCLabelEncode: null
      - SVTRRecResizeImg:
          image_shape:
            - 3
            - 32
            - 640
          padding: true
      - KeepKeys:
          keep_keys:
            - image
            - label
            - length
  sampler:
    name: DistributedCurriculumLengthSampler
  loader:
    shuffle: true
    batch_size_per_card: 48
    drop_last: true
    num_workers: 12

Eval:
  distributed: true
  dataset:
    name: LMDBDataSet
    data_dir: ./train_data/rec/val/
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - CTCLabelEncode: null
      - SVTRRecResizeImg:
          image_shape:
            - 3
            - 32
            - 640
          padding: true
      - KeepKeys:
          keep_keys:
            - image
            - label
            - length
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 512
    num_workers: 8
